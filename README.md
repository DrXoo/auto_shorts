# AutoShorts Pipeline ğŸ¬

Automated pipeline to convert podcast videos into vertical shorts ready for Instagram, TikTok, and YouTube Shorts.

## Pipeline Overview

```
Video Input
    â†“
[1] Transcribe with Speaker Diarization
    â†“
[2] AI Analysis (External) â†’ clips.json
    â†“
[3] Extract Clips
    â†“
[4] Crop to Vertical (9:16)
    â†“
[5] Add Karaoke Subtitles
    â†“
Final Shorts Ready! ğŸ‰
```

## âœ¨ Key Features

- **ğŸ™ï¸ Speaker-Aware Dynamic Cropping** - Intelligently shows 3 speakers at a time in episodes with 4-5 people, based on who's talking
- **ğŸ¯ Speaker Diarization** - Automatically identifies different speakers in your podcast
- **ğŸ¤– AI-Powered Clip Selection** - Provide clips.json for intelligent moment extraction
- **ğŸ“± Vertical Format Optimization** - Perfect 9:16 for Instagram Reels, TikTok, and YouTube Shorts
- **ğŸ“ Karaoke-Style Subtitles** - Word-by-word highlighting for maximum engagement
- **ğŸ”„ Multi-Scene Support** - Auto-detection or manual selection for different camera layouts
- **ğŸ® Trending Topics Integration** - Fetch gaming trends from Reddit, Steam, and YouTube
- **âš¡ GPU-Accelerated** - Fast transcription with CUDA support

### ğŸ†• Speaker-Aware Mode (4-5 Speakers)
For episodes with 4-5 people, the system analyzes the transcript and dynamically shows the 3 most relevant speakers at any given moment (active speaker + recently active ones). This works for BOTH scene types:
- **Speakers scene**: 3 most active in full discussion layout
- **Content scene**: Same 3 most active but with different crop positions/sizes to fit the content

See [SPEAKER_CONFIG_GUIDE.md](SPEAKER_CONFIG_GUIDE.md) for setup instructions.

## Quick Start

### Run Full Pipeline
```bash
python run_pipeline.py
```

The pipeline will:
1. âœ… Transcribe your video automatically
2. â¸ï¸ Wait for you to provide AI analysis (clips.json)
3. âœ… Extract, crop, and add subtitles automatically
4. ğŸ‰ Output final videos to `output/final/`

### Resume from Specific Step
```bash
python run_pipeline.py --from-step 3    # Resume from clip extraction
python run_pipeline.py --from-step 4    # Resume from cropping
```

### Skip Transcription
If you already have a transcript:
```bash
python run_pipeline.py --skip-transcribe
```

### Reset Pipeline State
```bash
python run_pipeline.py --reset
```

## Folder Structure

```
autoshorts/
â”œâ”€â”€ input/
â”‚   â””â”€â”€ example.mp4              # Your source video
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ transcripts/              # Transcription results
â”‚   â”‚   â”œâ”€â”€ example_transcript.json
â”‚   â”‚   â”œâ”€â”€ example_transcript.txt
â”‚   â”‚   â””â”€â”€ nexample_transcript_detailed.txt
â”‚   â”œâ”€â”€ ai_analysis/              # AI-selected clips
â”‚   â”‚   â””â”€â”€ clips.json            # â† YOU PROVIDE THIS
â”‚   â”œâ”€â”€ extracted/                # Raw extracted clips
â”‚   â”œâ”€â”€ cropped/                  # Vertical format clips
â”‚   â””â”€â”€ final/                    # Final videos with subtitles
â”‚       â””â”€â”€ clip_XX_title_subtitled.mp4  # â† UPLOAD THESE!
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ steps/                    # Pipeline steps (run by orchestrator)
â”‚   â”‚   â”œâ”€â”€ 1_transcribe.py
â”‚   â”‚   â”œâ”€â”€ 2_extract_clips.py
â”‚   â”‚   â”œâ”€â”€ 3_crop_to_vertical.py
â”‚   â”‚   â””â”€â”€ 4_add_subtitles.py
â”‚   â””â”€â”€ utils/                    # Utility scripts
â”‚       â”œâ”€â”€ aggregate_trending_topics.py
â”‚       â”œâ”€â”€ check_gpu.py
â”‚       â”œâ”€â”€ clean_output.py
â”‚       â”œâ”€â”€ find_crop_positions.py
â”‚       â””â”€â”€ fetch_*_trends.py
â””â”€â”€ run_pipeline.py              # ğŸš€ Main orchestrator
```

## Step 2: AI Analysis (Manual)

After transcription completes, you need to provide `output/ai_analysis/clips.json` with this format:

```json
[
  {
    "clip_number": 1,
    "title": "Amazing Discussion About AI",
    "start_time": "2:30",
    "end_time": "3:15"
  },
  {
    "clip_number": 2,
    "title": "Funny Moment",
    "start_time": "5:45",
    "end_time": "6:20"
  }
]
```

The pipeline will wait for this file and check periodically. Once detected, it continues automatically.

## Individual Scripts

You can still run individual steps manually:

```bash
# Step 1: Transcribe
python scripts/steps/1_transcribe.py

# Step 3: Extract clips
python scripts/steps/2_extract_clips.py

# Step 4: Crop to vertical
python scripts/steps/3_crop_to_vertical.py

# Step 5: Add subtitles
python scripts/steps/4_add_subtitles.py
```

## Utility Scripts

Helper scripts for various tasks:

```bash
# Check GPU availability for transcription
python scripts/utils/check_gpu.py

# Find optimal crop positions for your video layout
python scripts/utils/find_crop_positions.py

# Aggregate trending topics from all sources (Recommended!)
python scripts/utils/aggregate_trending_topics.py

# Fetch trending topics from individual sources
python scripts/utils/fetch_reddit_trends.py
python scripts/utils/fetch_steam_trends.py
python scripts/utils/fetch_youtube_trends.py

# Clean all output files (keeps folder structure)
python scripts/utils/clean_output.py
```

### Getting Trending Topics for AI Analysis

The `aggregate_trending_topics.py` script fetches gaming trends from:
- **Reddit** (r/gaming, r/Games, r/pcgaming, etc.)
- **Steam** (top sellers, new releases, most played)
- **YouTube** (trending gaming videos in Spanish market)

It combines and scores all results, giving you the **most relevant trending games** to help your AI identify viral-worthy clips. Run it before starting the pipeline to get the latest trends!

The output (`output/trending_topics.json`) includes:
- Top 50 trending games with scores
- Multi-source validation (games mentioned across platforms)
- Sample posts/videos mentioning each game
- Categorization (top seller, new release, etc.)

## Requirements

- Python 3.8+
- FFmpeg
- CUDA-capable GPU (for transcription)
- See individual scripts for Python package requirements

## Customization

### Subtitle Styling
Edit `scripts/steps/4_add_subtitles.py` to customize:
- Font family and size
- Colors (text, karaoke effect, outline)
- Position on screen
- Timing and grouping

### Crop Positions
Edit `scripts/steps/3_crop_to_vertical.py` to adjust:
- Single crop position (content sharing mode)
- Triple crop positions (speaker triangle mode)
- **Multi-speaker dynamic mode (4-5 people)** - See [SPEAKER_CONFIG_GUIDE.md](SPEAKER_CONFIG_GUIDE.md)
  - Configure number of speakers per episode
  - Map speaker IDs to camera positions
  - Adjust crop coordinates for your setup
- Auto-detection settings

## Output

Final videos are saved to `output/final/` with:
- âœ… Vertical 9:16 aspect ratio (810x1440)
- âœ… Karaoke-style subtitles
- âœ… Optimized for mobile viewing
- âœ… Ready to upload!

## Tips

1. **Place your video** in `input/example.mp4`
2. **Run the pipeline** with `python run_pipeline.py`
3. **Prepare clips.json** while waiting (use transcript output)
4. **Pipeline resumes** automatically after you provide clips.json
5. **Check `output/final/`** for your ready-to-upload shorts!

---

Made with â¤ï¸ for content creators
